{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9fb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'src' directory to Python's module search path\n",
    "src_dir = os.path.abspath(os.path.join(\"..\", \"src\"))  # Goes up to 'Challenge #1', then into 'src'\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cea4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from essentials import TinyVGG\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c57abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_cdf80d6f.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_c0142a80.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_91168fb0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_9822190f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_e5fc436c.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id\n",
       "0  img_cdf80d6f.jpeg\n",
       "1   img_c0142a80.jpg\n",
       "2   img_91168fb0.jpg\n",
       "3   img_9822190f.jpg\n",
       "4  img_e5fc436c.jpeg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "idx_to_class = {0: 'Alluvial soil', 1: 'Black Soil', 2: 'Clay soil', 3: 'Red soil'}\n",
    "\n",
    "test_ids_path = Path(r\"../data/data/soil_classification-2025\") / 'test_ids.csv'\n",
    "\n",
    "test_id = pd.read_csv(test_ids_path)\n",
    "test_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32e5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_vo = TinyVGG(3,10,4).to(device)\n",
    "\n",
    "state_dict = torch.load('best_model.pth')\n",
    "model_vo.load_state_dict(state_dict)\n",
    "\n",
    "for param in model_vo.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fcf3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 341/341 [00:06<00:00, 51.58it/s]\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "model_vo.eval()\n",
    "for i, (_, rows) in enumerate(tqdm(test_id.iterrows(), total=len(test_id), desc=\"Processing images\")):\n",
    "    img_id = rows['image_id']\n",
    "    img_path = Path(r\"../data/data/soil_classification-2025\") / \"test\" / img_id\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    t_image = transform(image)\n",
    "\n",
    "    b_image = t_image.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_logits = model_vo(b_image)\n",
    "\n",
    "    y_pred_class = torch.argmax(y_logits, dim=1).item()\n",
    "\n",
    "    labels.append(idx_to_class[y_pred_class])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14c7834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id['soil_type'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84db531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8244e327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>soil_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_cdf80d6f.jpeg</td>\n",
       "      <td>Alluvial soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_c0142a80.jpg</td>\n",
       "      <td>Alluvial soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_91168fb0.jpg</td>\n",
       "      <td>Alluvial soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_9822190f.jpg</td>\n",
       "      <td>Alluvial soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_e5fc436c.jpeg</td>\n",
       "      <td>Clay soil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id      soil_type\n",
       "0  img_cdf80d6f.jpeg  Alluvial soil\n",
       "1   img_c0142a80.jpg  Alluvial soil\n",
       "2   img_91168fb0.jpg  Alluvial soil\n",
       "3   img_9822190f.jpg  Alluvial soil\n",
       "4  img_e5fc436c.jpeg      Clay soil"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
